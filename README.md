### Architecture Diagram

     ai-backend-assessment-husseinAlshargi
    ├── .env
    ├── .gitignore
    ├── DELIVERABLES_CHECKLIST.md
    ├── manage.py                            # here CLI commands such as nightly-refresh can be done
    ├── requirements.txt                   # requirements needed to be installed in venv so that the project works
    ├── test.py                                  # carry out some tests here
    ├── evaluation.py                        # carry out some evaluation by running it
    ├── Makefile                               # carry out setup and run by it 
    ├── app
    │   ├── api                                         # api calls script 
    │   │   ├── admin
    │   │   │   ├── keys.py                        #  api keys functionalities
    │   │   │   └──  Schesuler.py               #  evaluation and nightly refresh
    │   │   └── user
    │   │   │   ├── message
    │   │   │   │   └── memory.py              # storing/getting messages, context, and summary
    │   │   │   └── report
    │   │   │       └── generate.py              # generating/ downloading docx reports
    │   │   ├── ask.py                                 # chat api call for generating an answer (get data related) to content
    │   │   └──  train_document.py             # adding documents to (training documents folder)
    │   ├── middleware
    │   │   └── api_key_auth.py                  #adding auth to api logic by adding headers (X-API-Key) also using the rate limiter function
    │   ├── models                                     #database tables
    │   │   ├── api_keys_record.py                #users' emails and their api keys (other columns also)
    │   │   ├── conversation_summary.py     #summuries of chats based on the turn number (other columns also)
    │   │   ├── document_chunk_record.py   # documents chuncks with their embeddings (other columns also)
    │   │   ├── ingested_file_record.py          # documents ingested with its tokens and hashes (other columns also)
    │   │   └── report_record.py                     # info about docx files (other columns also)
    │   ├── pages                                            #other pages but the main page (pages of streamlit side bar) you can notic the use from its' names
    │   │   ├── 1_Assisstant.py
    │   │   ├── 2_generate_report.py
    │   │   ├── 3_evaluate_report.py
    │   │   ├── 4_upload_training.py
    │   │   ├── 5_scheduler.py
    │   │   ├── 6_create_keys.py
    │   │   └── 7_manage_keys.py
    │   ├── retrieval                                           #retrive things (based on name) to be used in other python files
    │   │   ├── create_embeddings.py
    │   │   ├── generate_answer.py
    │   │   ├── generate_summary.py
    │   │   └── retrive_documents.py
    │   ├── schemas                                          # create db tables in db
    │   │   └── create_db_tables.py
    │   ├── scripts                                              #from its' name
    │   │   ├── create_api_key.py
    │   │   └── rate_limiter.py
    │   └── services                                             # to be used in api calls
    │   │   ├── evaluation.py
    │   │   ├──generate_report.py
    │   │   ├── ingestion.py
    │   │   ├── keyword_search.py
    │   │   ├── memory.py
    │   │   └── semantic_search.py
    │   ├── database.py                                       #database integration handled here
    │   ├── Home.py                                            #streamlit home page
    │   ├──main.py                                                #typer and api main objects are saved here 
    ├── benchmark
    │            ├── evaluation_report.md  # here the evaluation report is generated
    │            ├── questions.json             # evaluation is done based onquestionsn in this file
    ├── generated_reports
    │   ├── <files>                                  # docx reports generated by users are stored here
    ├── training_data 
    │      └── <files>                                # can contain folders with files to be used in ingestion


### Setup & run instructions
  - First thing to be able to run the project, you need to:
  -     1 -  download make: https://youtu.be/06D1tBKeTB4?si=DzPJgWz7EeIlCOV1
        2 -  download Ollama 8b
        3 -  download PostgreSQL
        4 -  Clone the repo
        5 -  Set up Redis db (could be on cloud)
        6 -  Create .env file that contains
             - PostgreSQL_host
             - PostgreSQL_port
             - PostgreSQL_username
             - PostgreSQL_dbname
             - PostgreSQL_password
             - Ollama_model
             - Ollama_base_url
             - REDIS_HOST
             - REDIS_PORT
             - REDIS_PASSWORD
         7 - Python 3.11+

    - Then simply use these commands in the terminal:
    -     1- To set up: make setup
          2- to run: make run
    
   - Those commands will do various things
   -     1- setup: 
          - Create a virtual environment 
          - Activate the virtual environment and install requirements.txt in it
          - Install llama3
          - Create tables in the DB.
          - IMPORTANT: Create an initial admin user. Then it will pass an admin api key in the terminal (you should keep it to use the APIs)

  -     2- run:
         - Start Ollama in the background
         - Start the api connection
         - Start streamlit server connection, which will open a website to test some of the functionalities


### nightly job 
  Simply using AsyncIOScheduler class: when the main app starts every day at 2 am ingestion, 3 am evaluation happens as long as the app is running at the time, or you could run it manually by using the api or from the streamlit ui or using the command (python manage.py nightly_refresh --now) in the terminal


### To add new data for the ingestion, you could simply use the ui section for that, or use the API
    @train_router.post("/training/accept")
    async def accept_training_document(
        file: Annotated[UploadFile, File(...)],
        tenant: Annotated[str, Form(...)]
    )

### Security and roles

All API calls require a header that contains an api key to make it secure and set the limit of the number of times a user can use it (initially 5 every 60 seconds)
Keep in notice that some of them require an admin role and another user role to be able to use it, like this app\admin\someapicall
Roles and api keys can be created from an api call specified in the architecture. or can be created using streamlit UI section taking only two args the rest is by default setted.
There is an api for activating or deactivating keys, which is also implemented in Streamlit UI.




### Important note about streamlit UI 
Not all APIs are included in the UI, it is just a simple UI that could improve significantly by adding a lot of features, like a live chat with a model, which is an important one.
about the last point some API's aren't included, such as memory API, which is about storing/getting messages, context, and summary as included in the architecture




